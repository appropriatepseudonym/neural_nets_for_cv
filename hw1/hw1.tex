

\section{Introduction}

The assignment given was to create, from scratch, code to predict images using K-Nearest-Neighbor (KNN). Images of cats, dogs, and pandas, one thousand each, were provided. The code was to import the images; randomly split the dataset into training (seventy percent), validation (ten percent), and test (twenty percent); determine the most effective k value using the test set against the validation set (using both L1-Manhattan and L2-Euclidean methods to determine distance); utilize those k values to predict the labels of the test images against the training images.  It was determined that Python 3.5 (coupled with OpenCV, sklearn, and numpy) would provide the best results. 

\section{Methods Used}

As stated previously, the KNN function was created from scratch. The sequence for the code is as follows:
Create the dataset:
	1. Import the images (using OpenCV) as numpy arrays
	2. Resize the image to 32x32x3 and flatten to a 1x3072 vector
	3. Append the vector to a list creating the dataset
Split the dataset:
	1. Use sklearn.model_selection's train_test_split to split data
		a. First split would seperate the test-set and the rest giving twenty-percent to the test-set
		b. The second call splits the remaining images into training-set and validation set. To achieve the ten percent, the test size was provided as 0.125; since $.125*2400=300$
` 